{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from dog_class import Mob_Dog\n",
    "from dog_class import apply_clahe_and_threshold\n",
    "from dog_class import apply_adaptive_threshold\n",
    "from dog_class import get_accuracy\n",
    "from torchvision.transforms.functional import to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((50, 50)), \n",
    "    transforms.Lambda(apply_clahe_and_threshold),  \n",
    "    transforms.ToTensor()  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mob_Dog(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1296, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (batchnorm1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm3): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm4): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 객체 생성, 옵티마이저 생성\n",
    "model = Mob_Dog()\n",
    "model = torch.load('model.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:183, y:28, w:147, h:187\n",
      "croped.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "isDragging = False                     \n",
    "x0, y0, w, h = -1,-1,-1,-1              \n",
    "blue, red = (255,0,0),(0,0,255)        \n",
    "\n",
    "def onMouse(event,x,y,flags,param):    \n",
    "    global isDragging, x0, y0, img      # 전역변수 참조\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # 왼쪽 마우스 버튼 다운\n",
    "        isDragging = True\n",
    "        x0 = x\n",
    "        y0 = y\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:  # 마우스 움직임\n",
    "        if isDragging:                  # 드래그 진행 중\n",
    "            img_draw = img.copy()\n",
    "            cv2.rectangle(img_draw, (x0, y0), (x, y), blue, 2) # 드래그 진행 영역 표시\n",
    "            cv2.imshow('img', img_draw) # 사각형 표시된 그림 화면 출력\n",
    "    elif event == cv2.EVENT_LBUTTONUP:  # 왼쪽 마우스 버튼 업\n",
    "        if isDragging:                  # 드래그 중지\n",
    "            isDragging = False          \n",
    "            w = x - x0                  # 폭 계산\n",
    "            h = y - y0                  # 높이 계산\n",
    "            print(\"x:%d, y:%d, w:%d, h:%d\" % (x0, y0, w, h))\n",
    "            if w > 0 and h > 0:   \n",
    "                img_draw = img.copy()   \n",
    "                cv2.rectangle(img_draw, (x0, y0), (x, y), red, 2) \n",
    "                cv2.imshow('img', img_draw) \n",
    "                roi = img[y0:y0+h, x0:x0+w] \n",
    "                cv2.imshow('cropped', roi)\n",
    "                cv2.moveWindow('cropped', 0, 0) \n",
    "                cv2.imwrite(param, roi)  \n",
    "                print(\"croped.\")\n",
    "            else:\n",
    "                cv2.imshow('img', img)\n",
    "                print(\"좌측 상단에서 우측 하단으로 영역을 드래그 하세요.\")\n",
    "\n",
    "\n",
    "try :\n",
    "    img = cv2.imread(\"./add_data/mop_dog/0.jpg\")\n",
    "    cv2.imshow('img', img)\n",
    "    cv2.setMouseCallback('img', onMouse, param=\"test.jpg\")\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "except : \n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88 확률로 강쥐!!!입니다!\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"test.jpg\")\n",
    "img_pil = to_pil_image(img)  \n",
    "\n",
    "transformed_img = transform(img_pil)  \n",
    "transformed_img = transformed_img.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(transformed_img)\n",
    "    _, predicted = torch.max(torch.softmax(output, dim=1).data, 1)\n",
    "    print(f\"{torch.softmax(output, dim=1).data[0][predicted].item():.2f} 확률로 {'강쥐!!!' if predicted.item() else '大걸레'}입니다!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
